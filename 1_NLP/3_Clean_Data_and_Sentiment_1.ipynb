{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7a523d80",
   "metadata": {},
   "source": [
    "# Necessary Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eee943c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b097bac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# nltk\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "import nltk.corpus\n",
    "nltk.download('stopwords')\n",
    "from nltk.stem.porter import *\n",
    "\n",
    "# feature extraction\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "from textblob import TextBlob\n",
    "\n",
    "# gensim\n",
    "import gensim\n",
    "from gensim import corpora, models, similarities, matutils\n",
    "\n",
    "# logging for gensim (set to INFO)\n",
    "import logging\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)\n",
    "\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "\n",
    "import sklearn.metrics as mt\n",
    "from sklearn.model_selection import cross_val_score, train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_recall_fscore_support as score\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import auc\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import precision_score, recall_score, accuracy_score, roc_auc_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler,MaxAbsScaler\n",
    "import string\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34fb56ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import emoji\n",
    "import re\n",
    "\n",
    "def strip_emoji(text):\n",
    "\n",
    "    print(emoji.emoji_count(text))\n",
    "\n",
    "    new_text = re.sub(emoji.get_emoji_regexp(), r\"\", text)\n",
    "\n",
    "    return new_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b944289",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"tripadvisor_hotel_review_combined.csv\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5693ebc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6020d1a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78eb4c33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of missing values in the dataset\n",
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91333ffa",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.Rating.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28898f28",
   "metadata": {},
   "source": [
    "# Clean Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a81d6937",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_url(txt):\n",
    "    url = re.compile(r'https?://\\S+|www\\.\\S+')\n",
    "    return url.sub(r'',txt)\n",
    "\n",
    "def remove_html(txt):\n",
    "    html=re.compile(r'<.*?>')\n",
    "    return html.sub(r'',txt)\n",
    "\n",
    "# U+1F970\n",
    "def remove_emoji(txt):\n",
    "    emoji_pattern = re.compile(\"[\"\n",
    "                           u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "                           u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "                           u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "                           u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "                           u\"\\U00002702-\\U000027B0\"\n",
    "                           u\"\\U000024C2-\\U0001F251\"\n",
    "                           \"]+\", flags=re.UNICODE)\n",
    "    return emoji_pattern.sub(r'', txt)\n",
    "def remove(emoji):\n",
    "    em = re.compile(r\"ðŸ¥°\")\n",
    "    return em.sub(r\"\",emoji)\n",
    "def remove_blank_space(text):\n",
    "    return re.sub(\"\\s\\s+\" , \" \", text)\n",
    "def remove_blank2(text):\n",
    "    text = text.strip()\n",
    "    return text\n",
    "def remove_all(ReviewText):\n",
    "    ReviewText = ReviewText.replace(\"(<br/>)\", \"\")\n",
    "    ReviewText = ReviewText.replace('(<a).*(>).*(</a>)', '')\n",
    "    ReviewText = ReviewText.replace('(&amp)', '')\n",
    "    ReviewText = ReviewText.replace('(&gt)', '')\n",
    "    ReviewText = ReviewText.replace('(&lt)', '')\n",
    "    ReviewText = ReviewText.replace('(\\xa0)', ' ') \n",
    "    ReviewText = ReviewText.replace(r'http[s]?://(?:[a-z]|[0-9]|[$-_@.&amp;+]|[!*\\(\\),]|(?:%[0-9a-f][0-9a-f]))+', ' ') \n",
    "    return ReviewText\n",
    "\n",
    "from wordcloud import STOPWORDS\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download(\"stopwords\")\n",
    "\n",
    "s_words= list(stopwords.words('english'))\n",
    "stop_words = list(STOPWORDS)+ [\"what\", \"us\", \"this\",\"well\",\"there\",\"much\",\"us\",\"and\",\"you're\",\"in\",\"where\",\"when\",\"just\",\"how\",\"is\",\"ha\",\"re\",\"are\"\n",
    "                              \"hi\",\"aren't\", 'couldn','could','couldnt',\"couldn't\",'did','had','have','must','does','should','was',\"it's\"\n",
    "                               \"didn't\", \"doesn't\", \"don't\", \"hadn't\", \"hasn't\", \"haven't\", \"isn't\", 'let', 'll',\"may\",'were','is','has','must',\n",
    "                               'mustn', 'rt', 'shan', 'shouldn', 'wasn', 'weren', 'won', 'wouldn','realli','now','got','man','people','a',\n",
    "                               'becaus','caus',\"one\",\"im\",\"guy\",\"someone\",\"two\",\"nearby\",\"i\",\"he's\",\"she's\",\"we\",\"it\",\"they\",\"wouldnâ€™t\",\"i've\",\n",
    "                               'aren', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'sdidn', 've',\"will\",\"restaurant\"]\n",
    "\n",
    "\n",
    "\n",
    "def remove_stopwords(txt):\n",
    "    \n",
    "    sentence = []\n",
    "    s = \"\"\n",
    "    for word in txt.split():    \n",
    "        if(word not in stop_words):      \n",
    "            sentence.append(word)\n",
    "            s = ' '.join(sentence)\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "447edada",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.Review = df.Review.apply(remove_url)\n",
    "df.Review = df.Review.apply(remove_html)\n",
    "df.Review = df.Review.apply(remove_emoji)\n",
    "df.Review = df.Review.apply(remove)\n",
    "df.Review = df.Review.apply(remove_blank_space)\n",
    "df.Review = df.Review.apply(remove_blank2)\n",
    "df.Review = df.Review.apply(remove_all)\n",
    "df.Review = df.Review.map(remove_stopwords)\n",
    "df.Review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50121875",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_data = df[['Rating','Review','Hotel_Name']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d471b84",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_data.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c3a34b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "sdata = sentiment_data.values    # Gives a numpy array\n",
    "count = len(sdata)\n",
    "all_data = []\n",
    "\n",
    "for i in range(count):\n",
    "    rating = sdata[i, 0]\n",
    "    hotel_name = sdata[i, 2]\n",
    "    reviews = sdata[i, 1].split('], [')[0]     # Splitting the reviews and date strings from a single list and considering only the reviews\n",
    "    reviews = reviews.replace(\"[[\", \"\")\n",
    "    reviews = reviews.replace(\"'\", \"\")\n",
    "    reviews = reviews.replace('\"', '')\n",
    "    reviews = reviews.split(',')\n",
    "    print(reviews)\n",
    "    for review in reviews:\n",
    "        all_data.append([review, rating, hotel_name])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a72f73fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2089b3bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "sent_data = pd.DataFrame(all_data, columns = ['Review', 'Rating','Hotel_Name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb83eb7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sent_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b8fd64e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenization\n",
    "# Splitting sentences into list of individual words  \n",
    "tokenized_data = sent_data['Review'].apply(lambda x : x.lower().split())    \n",
    "tokenized_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "776351d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stemming\n",
    "# Reducing a word to its stem word\n",
    "stemmer = PorterStemmer()\n",
    "stem_data = tokenized_data.apply(lambda x: [stemmer.stem(i) for i in x])  \n",
    "stem_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6088d52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Joining the stemmed words to reframe sentences\n",
    "stemmed_data = []\n",
    "for i in range(len(stem_data)):\n",
    "    stemmed_data.append(' '.join(stem_data[i]))    \n",
    "\n",
    "stemmed_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ada72c54",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(stemmed_data).reshape(-1,1)   # Converting into a numpy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c0a616a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sent_data['Cleaned_Review'] = np.array(stemmed_data).reshape(-1,1)  # Reshaping"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fa8d449",
   "metadata": {},
   "source": [
    "# Visualizing customer reviews using WordCloud module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7bd7781",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ALl the stemmed words in reviews \n",
    "all_words = ' '.join([text for text in sent_data['Cleaned_Review']])    #stemmed words\n",
    "\n",
    "from wordcloud import WordCloud\n",
    "wordcloud = WordCloud(width=800, height=500, random_state=21, max_font_size=110).generate(all_words)\n",
    "\n",
    "plt.figure(figsize=(10, 7))\n",
    "plt.imshow(wordcloud, interpolation=\"bilinear\")\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28616948",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Words used by the customers in reviews corresponding to rating 5\n",
    "# Rating the restaurants as excellent\n",
    "hide_words = ' '.join([text for text in sent_data['Cleaned_Review'][sent_data['Hotel_Name'] == 'HIDE BANGKOK HOSTEL']])\n",
    "\n",
    "wordcloud = WordCloud(width=800, height=500, random_state=21, max_font_size=110).generate(hide_words)\n",
    "plt.figure(figsize=(10, 7))\n",
    "plt.imshow(wordcloud, interpolation=\"bilinear\")\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f97a0724",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Words used by the customers in reviews corresponding to rating 5\n",
    "# Rating the restaurants as excellent\n",
    "excellent_words = ' '.join([text for text in sent_data['Cleaned_Review'][sent_data['Rating'] == 50]])\n",
    "\n",
    "wordcloud = WordCloud(width=800, height=500, random_state=21, max_font_size=110).generate(excellent_words)\n",
    "plt.figure(figsize=(10, 7))\n",
    "plt.imshow(wordcloud, interpolation=\"bilinear\")\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c30a20f9",
   "metadata": {},
   "source": [
    "# Sentiment Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13ece772",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "nltk.download('vader_lexicon')\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "\n",
    "sid = SentimentIntensityAnalyzer()\n",
    "\n",
    "listy = []\n",
    "\n",
    "for index, row in sent_data.iterrows():\n",
    "  ss = sid.polarity_scores(row[\"Cleaned_Review\"])\n",
    "  listy.append(ss)\n",
    "  \n",
    "se = pd.Series(listy)\n",
    "sent_data['polarity'] = se.values\n",
    "\n",
    "display(sent_data.head(100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64547276",
   "metadata": {},
   "outputs": [],
   "source": [
    "sent_data.to_csv('Trip_advisor_sentiment.csv', encoding='utf-8')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
